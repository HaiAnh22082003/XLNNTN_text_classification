{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import underthesea\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = underthesea.word_tokenize(text)\n",
    "    # print(\"Lower\",tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(tokens):\n",
    "    with open(\"vietnamese-stopwords.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]\n",
    "    final_tokens = [token for token in tokens if token not in stopwords]\n",
    "    final_text = ' '.join(final_tokens)\n",
    "    # print(\"Stopword\",final_text)\n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Crawl/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19805 entries, 0 to 19804\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  19805 non-null  object\n",
      " 1   Nội dung  19805 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 309.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Danh mục\n",
       "Văn hóa     2823\n",
       "Xe          2466\n",
       "Giới trẻ    2460\n",
       "Thể thao    2041\n",
       "Sức khỏe    1906\n",
       "Giáo dục    1862\n",
       "Thế giới    1732\n",
       "Thời sự     1520\n",
       "Giải trí    1002\n",
       "Đời sống     979\n",
       "Kinh tế      819\n",
       "Du lịch      195\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Danh mục'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19805 entries, 0 to 19804\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  19805 non-null  object\n",
      " 1   Nội dung  19805 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 309.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=df['Nội dung'].apply(lambda x: lower_tokenize(x))\n",
    "content=content.apply(lambda x: remove_stopword(x))\n",
    "label=df['Danh mục']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        nttt ngụ phú nhuận tphcm bệnh nhân bệnh thoát ...\n",
       "1        sóng gió đời tư ngọc trinh trở lại vai diễn út...\n",
       "2        phó tổng thống philippines sara duterteảnh reu...\n",
       "3        dự thảo quy chế tổ chức thi chứng chỉ ngoại ng...\n",
       "4        kem trị sẹo thâm chân mua kem trị sẹo thâm châ...\n",
       "                               ...                        \n",
       "19800    những tưởng âm thầm biến danh mục sản phẩm yam...\n",
       "19801    sụt giảm ô tô nhập khẩu việt nam đà tăng trưởn...\n",
       "19802                                                     \n",
       "19803    nhu cầu đa dạng khách hàng việt nam doanh nghi...\n",
       "19804    đọc viết phân biệt đối xử khách hàng việt nam ...\n",
       "Name: Nội dung, Length: 19805, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sức khỏe\n",
       "1        Giải trí\n",
       "2        Thế giới\n",
       "3        Giáo dục\n",
       "4        Sức khỏe\n",
       "           ...   \n",
       "19800          Xe\n",
       "19801          Xe\n",
       "19802          Xe\n",
       "19803          Xe\n",
       "19804          Xe\n",
       "Name: Danh mục, Length: 19805, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(content, label, test_size=0.3, random_state=10)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "# Mã hóa nhãn mục tiêu\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13863, 5000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5942, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huấn luyện mô hình Naive Bayes\n",
    "MultiNB = naive_bayes.MultinomialNB(alpha=0.2)\n",
    "# fit the training dataset on the classifier\n",
    "MultiNB.fit(X_train_tfidf, y_train)\n",
    "# Dự đoán nhãn\n",
    "predictions_nb = MultiNB.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá bằng: Accuracy: 0.8232918209357118\n",
      "Đánh giá bằng: Precision: 0.8222117005270214\n",
      "Đánh giá bằng: Recall: 0.8232918209357118\n",
      "Đánh giá bằng: F1 Score: 0.8213610897950248\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(predictions_nb, y_test)\n",
    "print(f\"Đánh giá bằng: Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: Recall: {recall}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung:  học toán\n",
      "Dự đoán danh mục:  Giáo dục\n",
      "----------------------------------------\n",
      "Nội dung:  việt nam sân thắng lào tỉ số\n",
      "Dự đoán danh mục:  Thể thao\n",
      "----------------------------------------\n",
      "Nội dung:  bạo lực học đường\n",
      "Dự đoán danh mục:  Giáo dục\n",
      "----------------------------------------\n",
      "Nội dung:  xe ariblade cc ngoại hình siêu đẹp\n",
      "Dự đoán danh mục:  Xe\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị dữ liệu kiểm thử mới\n",
    "new_data = [\"Tôi thích học Toán\",\n",
    "            \"VIệt Nam ra sân thắng Lào với tỉ số 10-0\",\n",
    "            \"Bạo lực học đường là vấn đề được quan tâm nhất hiện nay\",\n",
    "            \"Xe Ariblade 165CC có ngoại hình siêu đẹp\"]\n",
    "\n",
    "# Tiền xử lý dữ liệu kiểm thử mới\n",
    "new_data= [lower_tokenize(text) for text in new_data]\n",
    "new_data = [remove_stopword(tokens) for tokens in new_data] # Loại bỏ stop words\n",
    "# Chuyển đổi dữ liệu kiểm thử mới thành đặc trưng TF-IDF\n",
    "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
    "\n",
    "# Dự đoán nhãn với dữ liệu kiểm thử mới\n",
    "new_predictions = MultiNB.predict(new_data_tfidf)\n",
    "\n",
    "# Chuyển đổi nhãn được dự đoán về dạng ban đầu\n",
    "new_predictions_labels = encoder.inverse_transform(new_predictions)\n",
    "# In ra các dự đoán\n",
    "for i, text in enumerate(new_data):\n",
    "    print(f\"Nội dung: \",text)\n",
    "    print(f\"Dự đoán danh mục: \",new_predictions_labels[i])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((tfidf_vectorizer,MultiNB,encoder), \"model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
